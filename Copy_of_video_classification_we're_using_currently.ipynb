{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of video_classification_we're using currently",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akshitadixit/RAKSHA-3.0/blob/main/Copy_of_video_classification_we're_using_currently.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09mJ3wdZWGdn"
      },
      "source": [
        "This example demonstrates video classification, an important use-case with\n",
        "applications in recommendations, security, and so on.\n",
        "We will be using the [UCF101 dataset](https://www.crcv.ucf.edu/data/UCF101.php)\n",
        "to build our video classifier. The dataset consists of videos categorized into different\n",
        "actions, like cricket shot, punching, biking, etc. This dataset is commonly used to\n",
        "build action recognizers, which are an application of video classification.\n",
        "\n",
        "A video consists of an ordered sequence of frames. Each frame contains *spatial*\n",
        "information, and the sequence of those frames contains *temporal* information. To model\n",
        "both of these aspects, we use a hybrid architecture that consists of convolutions\n",
        "(for spatial processing) as well as recurrent layers (for temporal processing).\n",
        "Specifically, we'll use a Convolutional Neural Network (CNN) and a Recurrent Neural\n",
        "Network (RNN) consisting of [GRU layers](https://keras.io/api/layers/recurrent_layers/gru/).\n",
        "This kind of hybrid architecture is popularly known as a **CNN-RNN**.\n",
        "\n",
        "This example requires TensorFlow 2.5 or higher, as well as TensorFlow Docs, which can be\n",
        "installed using the following command:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaGBRL-fWGdq",
        "outputId": "f565daba-6c06-4d77-9547-2a77029fcc0a"
      },
      "source": [
        "!pip install -q git+https://github.com/tensorflow/docs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Building wheel for tensorflow-docs (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5-88AXeX48M"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras import backend as K\n",
        "import sys\n",
        "import csv\n",
        "import os\n",
        "\n",
        "import cv2\n",
        "import math\n",
        "import random\n",
        "import datetime as dt\n",
        "import tensorflow as tf\n",
        "from collections import deque\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.utils import plot_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxsWC5DnWGdu"
      },
      "source": [
        "## Data collection\n",
        "\n",
        "In order to keep the runtime of this example relatively short, we will be using a\n",
        "subsampled version of the original UCF101 dataset. You can refer to\n",
        "[this notebook](https://colab.research.google.com/github/sayakpaul/Action-Recognition-in-TensorFlow/blob/main/Data_Preparation_UCF101.ipynb)\n",
        "to know how the subsampling was done."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hd5ixKK8WGdw",
        "outputId": "a8aff983-5a3e-4f86-90fa-5383f011a276"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "dataset_dir = '/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JS5wnloM2ilx"
      },
      "source": [
        "classes = ['Hammer Strike','Groin Kick','Heel Palm Strike','Elbow Strike','Escape Bear Hug Attack','Escape Hands Trapped','Escape Side Headlock','Eye Strike','Knee strike','Ready Stance','Two handed choked']\n",
        "\n",
        "with open(dataset_dir+'dataset.csv', 'w', newline='') as file:\n",
        "  writer = csv.writer(file)\n",
        "  for c in classes:\n",
        "    path = os.path.join(dataset_dir,c)\n",
        "    for i in os.listdir(path):\n",
        "      writer.writerow([classes.index(c), os.path.join(path, i)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVzJzJfyXj_G",
        "outputId": "cd05f7ef-54e5-4afb-e569-9fdffa485787"
      },
      "source": [
        "df = pd.read_csv(dataset_dir+'dataset.csv', header=None)\n",
        "df.columns = [\"class\", \"path\"]\n",
        "df = df.astype({\"class\": str})\n",
        "\n",
        "# changing path from mp4 to avi\n",
        "#df[\"path\"] = df[\"path\"].apply(lambda x: x.replace(\"mp4\", \"avi\"))\n",
        "\n",
        "#df = df.append(df, ignore_index=True)\n",
        "#df = df.append(df, ignore_index=True)\n",
        "print(len(df))\n",
        "print(df)\n",
        "\n",
        "# split the data\n",
        "train, test = np.split(df.sample(frac=1, random_state=42), [int(.857*len(df))])\n",
        "print(len(train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "305\n",
            "    class                                               path\n",
            "0       0  /content/gdrive/My Drive/Colab Notebooks/Pose/...\n",
            "1       0  /content/gdrive/My Drive/Colab Notebooks/Pose/...\n",
            "2       0  /content/gdrive/My Drive/Colab Notebooks/Pose/...\n",
            "3       0  /content/gdrive/My Drive/Colab Notebooks/Pose/...\n",
            "4       0  /content/gdrive/My Drive/Colab Notebooks/Pose/...\n",
            "..    ...                                                ...\n",
            "300    10  /content/gdrive/My Drive/Colab Notebooks/Pose/...\n",
            "301    10  /content/gdrive/My Drive/Colab Notebooks/Pose/...\n",
            "302    10  /content/gdrive/My Drive/Colab Notebooks/Pose/...\n",
            "303    10  /content/gdrive/My Drive/Colab Notebooks/Pose/...\n",
            "304    10  /content/gdrive/My Drive/Colab Notebooks/Pose/...\n",
            "\n",
            "[305 rows x 2 columns]\n",
            "261\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCHV7V7yWGdx"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-x2AWRVeWGdz"
      },
      "source": [
        "from tensorflow_docs.vis import embed\n",
        "from tensorflow import keras\n",
        "from imutils import paths\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import imageio\n",
        "import cv2\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38sbeZRPWGd0"
      },
      "source": [
        "## Define hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3-OG97_WGd1"
      },
      "source": [
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 20\n",
        "\n",
        "MAX_SEQ_LENGTH = 240\n",
        "NUM_FEATURES = 2048"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wu-w1ZNMWGd4"
      },
      "source": [
        "## Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "G8-C8nxRWGd5",
        "outputId": "b9b4c0b6-bb04-4cd5-f2d7-64f363fa37b5"
      },
      "source": [
        "train_df = train\n",
        "test_df = test\n",
        "\n",
        "print(f\"Total videos for training: {len(train_df)}\")\n",
        "print(f\"Total videos for testing: {len(test_df)}\")\n",
        "\n",
        "train_df.sample(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total videos for training: 261\n",
            "Total videos for testing: 44\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>254</th>\n",
              "      <td>8</td>\n",
              "      <td>/content/gdrive/My Drive/Colab Notebooks/Pose/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>236</th>\n",
              "      <td>8</td>\n",
              "      <td>/content/gdrive/My Drive/Colab Notebooks/Pose/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>1</td>\n",
              "      <td>/content/gdrive/My Drive/Colab Notebooks/Pose/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>2</td>\n",
              "      <td>/content/gdrive/My Drive/Colab Notebooks/Pose/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>300</th>\n",
              "      <td>10</td>\n",
              "      <td>/content/gdrive/My Drive/Colab Notebooks/Pose/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>7</td>\n",
              "      <td>/content/gdrive/My Drive/Colab Notebooks/Pose/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156</th>\n",
              "      <td>6</td>\n",
              "      <td>/content/gdrive/My Drive/Colab Notebooks/Pose/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>/content/gdrive/My Drive/Colab Notebooks/Pose/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>1</td>\n",
              "      <td>/content/gdrive/My Drive/Colab Notebooks/Pose/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129</th>\n",
              "      <td>4</td>\n",
              "      <td>/content/gdrive/My Drive/Colab Notebooks/Pose/...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    class                                               path\n",
              "254     8  /content/gdrive/My Drive/Colab Notebooks/Pose/...\n",
              "236     8  /content/gdrive/My Drive/Colab Notebooks/Pose/...\n",
              "66      1  /content/gdrive/My Drive/Colab Notebooks/Pose/...\n",
              "77      2  /content/gdrive/My Drive/Colab Notebooks/Pose/...\n",
              "300    10  /content/gdrive/My Drive/Colab Notebooks/Pose/...\n",
              "197     7  /content/gdrive/My Drive/Colab Notebooks/Pose/...\n",
              "156     6  /content/gdrive/My Drive/Colab Notebooks/Pose/...\n",
              "5       0  /content/gdrive/My Drive/Colab Notebooks/Pose/...\n",
              "63      1  /content/gdrive/My Drive/Colab Notebooks/Pose/...\n",
              "129     4  /content/gdrive/My Drive/Colab Notebooks/Pose/..."
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ba1mMJQtWGd6"
      },
      "source": [
        "One of the many challenges of training video classifiers is figuring out a way to feed\n",
        "the videos to a network. [This blog post](https://blog.coast.ai/five-video-classification-methods-implemented-in-keras-and-tensorflow-99cad29cc0b5)\n",
        "discusses five such methods. Since a video is an ordered sequence of frames, we could\n",
        "just extract the frames and put them in a 3D tensor. But the number of frames may differ\n",
        "from video to video which would prevent us from stacking them into batches\n",
        "(unless we use padding). As an alternative, we can **save video frames at a fixed\n",
        "interval until a maximum frame count is reached**. In this example we will do\n",
        "the following:\n",
        "\n",
        "1. Capture the frames of a video.\n",
        "2. Extract frames from the videos until a maximum frame count is reached.\n",
        "3. In the case, where a video's frame count is lesser than the maximum frame count we\n",
        "will pad the video with zeros.\n",
        "\n",
        "Note that this workflow is identical to [problems involving texts sequences](https://developers.google.com/machine-learning/guides/text-classification/). Videos of the UCF101 dataset is [known](https://www.crcv.ucf.edu/papers/UCF101_CRCV-TR-12-01.pdf)\n",
        "to not contain extreme variations in objects and actions across frames. Because of this,\n",
        "it may be okay to only consider a few frames for the learning task. But this approach may\n",
        "not generalize well to other video classification problems. We will be using\n",
        "[OpenCV's `VideoCapture()` method](https://docs.opencv.org/master/dd/d43/tutorial_py_video_display.html)\n",
        "to read frames from videos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpGR4zhpWGd7"
      },
      "source": [
        "# The following two methods are taken from this tutorial:\n",
        "# https://www.tensorflow.org/hub/tutorials/action_recognition_with_tf_hub\n",
        "\n",
        "\n",
        "def crop_center_square(frame):\n",
        "    y, x = frame.shape[0:2]\n",
        "    min_dim = min(y, x)\n",
        "    start_x = (x // 2) - (min_dim // 2)\n",
        "    start_y = (y // 2) - (min_dim // 2)\n",
        "    return frame[start_y : start_y + min_dim, start_x : start_x + min_dim]\n",
        "\n",
        "\n",
        "def load_video(path, max_frames=0, resize=(IMG_SIZE, IMG_SIZE)):\n",
        "    cap = cv2.VideoCapture(path)\n",
        "    frames = []\n",
        "    try:\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "            frame = crop_center_square(frame)\n",
        "            frame = cv2.resize(frame, resize)\n",
        "            frame = frame[:, :, [2, 1, 0]]\n",
        "            frames.append(frame)\n",
        "\n",
        "            if len(frames) == max_frames:\n",
        "                break\n",
        "    finally:\n",
        "        cap.release()\n",
        "    return np.array(frames)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgz74zmqWGd9"
      },
      "source": [
        "We can use a pre-trained network to extract meaningful features from the extracted\n",
        "frames. The [`Keras Applications`](https://keras.io/api/applications/) module provides\n",
        "a number of state-of-the-art models pre-trained on the [ImageNet-1k dataset](http://image-net.org/).\n",
        "We will be using the [InceptionV3 model](https://arxiv.org/abs/1512.00567) for this purpose."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ku80miRZWGd9",
        "outputId": "84a40c2f-ff13-4f6f-feb4-712f7fcd46bb"
      },
      "source": [
        "\n",
        "def build_feature_extractor():\n",
        "    feature_extractor = keras.applications.InceptionV3(\n",
        "        weights=\"imagenet\",\n",
        "        include_top=False,\n",
        "        pooling=\"avg\",\n",
        "        input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
        "    )\n",
        "    preprocess_input = keras.applications.inception_v3.preprocess_input\n",
        "\n",
        "    inputs = keras.Input((IMG_SIZE, IMG_SIZE, 3))\n",
        "    preprocessed = preprocess_input(inputs)\n",
        "\n",
        "    outputs = feature_extractor(preprocessed)\n",
        "    return keras.Model(inputs, outputs, name=\"feature_extractor\")\n",
        "\n",
        "\n",
        "feature_extractor = build_feature_extractor()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 1s 0us/step\n",
            "87924736/87910968 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QLZCZTlWGd-"
      },
      "source": [
        "The labels of the videos are strings. Neural networks do not understand string values,\n",
        "so they must be converted to some numerical form before they are fed to the model. Here\n",
        "we will use the [`StringLookup`](https://keras.io/api/layers/preprocessing_layers/categorical/string_lookup)\n",
        "layer encode the class labels as integers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3_nL1ifWGd-",
        "outputId": "be944510-acb9-4ce0-b249-d1f0038498c1"
      },
      "source": [
        "label_processor = keras.layers.StringLookup(\n",
        "    num_oov_indices=0, vocabulary=np.unique(train_df[\"class\"])\n",
        ")\n",
        "print(label_processor.get_vocabulary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['0', '1', '10', '2', '3', '4', '5', '6', '7', '8', '9']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgmpWOcpWGeA"
      },
      "source": [
        "Finally, we can put all the pieces together to create our data processing utility."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "rT6Z-NycWGeA",
        "outputId": "7610660c-7bbe-45aa-b4b2-6071b19e7383"
      },
      "source": [
        "\n",
        "def prepare_all_videos(df, root_dir):\n",
        "    num_samples = len(df)\n",
        "    video_paths = df[\"path\"].values.tolist()\n",
        "    labels = df[\"class\"].values\n",
        "    labels = label_processor(labels[..., None]).numpy()\n",
        "\n",
        "    # `frame_masks` and `frame_features` are what we will feed to our sequence model.\n",
        "    # `frame_masks` will contain a bunch of booleans denoting if a timestep is\n",
        "    # masked with padding or not.\n",
        "    frame_masks = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH), dtype=\"bool\")\n",
        "    frame_features = np.zeros(\n",
        "        shape=(num_samples, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\"\n",
        "    )\n",
        "\n",
        "    # For each video.\n",
        "    for idx, path in enumerate(video_paths):\n",
        "        # Gather all its frames and add a batch dimension.\n",
        "        frames = load_video(os.path.join(root_dir, path))\n",
        "        frames = frames[None, ...]\n",
        "\n",
        "        # Initialize placeholders to store the masks and features of the current video.\n",
        "        temp_frame_mask = np.zeros(shape=(1, MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
        "        temp_frame_features = np.zeros(\n",
        "            shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\"\n",
        "        )\n",
        "\n",
        "        # Extract features from the frames of the current video.\n",
        "        for i, batch in enumerate(frames):\n",
        "            video_length = batch.shape[0]\n",
        "            length = min(MAX_SEQ_LENGTH, video_length)\n",
        "            for j in range(length):\n",
        "                temp_frame_features[i, j, :] = feature_extractor.predict(\n",
        "                    batch[None, j, :]\n",
        "                )\n",
        "            temp_frame_mask[i, :length] = 1  # 1 = not masked, 0 = masked\n",
        "\n",
        "        frame_features[idx,] = temp_frame_features.squeeze()\n",
        "        frame_masks[idx,] = temp_frame_mask.squeeze()\n",
        "        print(idx)\n",
        "    return (frame_features, frame_masks), labels\n",
        "\n",
        "\n",
        "train_data, train_labels = prepare_all_videos(train_df, \"train\")\n",
        "print(\"train done.... \")\n",
        "test_data, test_labels = prepare_all_videos(test_df, \"test\")\n",
        "\n",
        "print(f\"Frame features in train set: {train_data[0].shape}\")\n",
        "print(f\"Frame masks in train set: {train_data[1].shape}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "125\n",
            "126\n",
            "127\n",
            "128\n",
            "129\n",
            "130\n",
            "131\n",
            "132\n",
            "133\n",
            "134\n",
            "135\n",
            "136\n",
            "137\n",
            "138\n",
            "139\n",
            "140\n",
            "141\n",
            "142\n",
            "143\n",
            "144\n",
            "145\n",
            "146\n",
            "147\n",
            "148\n",
            "149\n",
            "150\n",
            "151\n",
            "152\n",
            "153\n",
            "154\n",
            "155\n",
            "156\n",
            "157\n",
            "158\n",
            "159\n",
            "160\n",
            "161\n",
            "162\n",
            "163\n",
            "164\n",
            "165\n",
            "166\n",
            "167\n",
            "168\n",
            "169\n",
            "170\n",
            "171\n",
            "172\n",
            "173\n",
            "174\n",
            "175\n",
            "176\n",
            "177\n",
            "178\n",
            "179\n",
            "180\n",
            "181\n",
            "182\n",
            "183\n",
            "184\n",
            "185\n",
            "186\n",
            "187\n",
            "188\n",
            "189\n",
            "190\n",
            "191\n",
            "192\n",
            "193\n",
            "194\n",
            "195\n",
            "196\n",
            "197\n",
            "198\n",
            "199\n",
            "200\n",
            "201\n",
            "202\n",
            "203\n",
            "204\n",
            "205\n",
            "206\n",
            "207\n",
            "208\n",
            "209\n",
            "210\n",
            "211\n",
            "212\n",
            "213\n",
            "214\n",
            "215\n",
            "216\n",
            "217\n",
            "218\n",
            "219\n",
            "220\n",
            "221\n",
            "222\n",
            "223\n",
            "224\n",
            "225\n",
            "226\n",
            "227\n",
            "228\n",
            "229\n",
            "230\n",
            "231\n",
            "232\n",
            "233\n",
            "234\n",
            "235\n",
            "236\n",
            "237\n",
            "238\n",
            "239\n",
            "240\n",
            "241\n",
            "242\n",
            "243\n",
            "244\n",
            "245\n",
            "246\n",
            "247\n",
            "248\n",
            "249\n",
            "250\n",
            "251\n",
            "252\n",
            "253\n",
            "254\n",
            "255\n",
            "256\n",
            "257\n",
            "258\n",
            "259\n",
            "260\n",
            "train done.... \n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "Frame features in train set: (261, 240, 2048)\n",
            "Frame masks in train set: (261, 240)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5A7QuynWGeC"
      },
      "source": [
        "The above code block will take ~20 minutes to execute depending on the machine it's being\n",
        "executed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTSSjvMpWGeD"
      },
      "source": [
        "## The sequence model\n",
        "\n",
        "Now, we can feed this data to a sequence model consisting of recurrent layers like `GRU`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldrUghjYWGeD",
        "outputId": "92a80255-bc64-4407-ee5e-bfc2f31b4609"
      },
      "source": [
        "# Utility for our sequence model.\n",
        "def get_sequence_model():\n",
        "    class_vocab = label_processor.get_vocabulary()\n",
        "\n",
        "    frame_features_input = keras.Input((MAX_SEQ_LENGTH, NUM_FEATURES))\n",
        "    mask_input = keras.Input((MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
        "\n",
        "    # Refer to the following tutorial to understand the significance of using `mask`:\n",
        "    # https://keras.io/api/layers/recurrent_layers/gru/\n",
        "    x = keras.layers.GRU(16, return_sequences=True)(\n",
        "        frame_features_input, mask=mask_input\n",
        "    )\n",
        "    x = keras.layers.GRU(256)(x)\n",
        "    x = keras.layers.Dropout(0.4)(x)\n",
        "    x = keras.layers.Dense(2048, activation=\"relu\")(x)\n",
        "    output = keras.layers.Dense(len(class_vocab), activation=\"softmax\")(x)\n",
        "\n",
        "    rnn_model = keras.Model([frame_features_input, mask_input], output)\n",
        "\n",
        "    rnn_model.compile(\n",
        "        loss=\"hinge\", optimizer=keras.optimizers.Adam(learning_rate=10e-5), metrics=[\"accuracy\"]\n",
        "    )\n",
        "    return rnn_model\n",
        "\n",
        "\n",
        "# Utility for running experiments.\n",
        "def run_experiment():\n",
        "    filepath = \"/tmp/video_classifier\"\n",
        "    checkpoint = keras.callbacks.ModelCheckpoint(\n",
        "        filepath, save_weights_only=True, save_best_only=True, verbose=1\n",
        "    )\n",
        "\n",
        "    seq_model = get_sequence_model()\n",
        "    history = seq_model.fit(\n",
        "        [train_data[0], train_data[1]],\n",
        "        train_labels,\n",
        "        validation_split=0.3,\n",
        "        epochs=EPOCHS,\n",
        "        callbacks=[checkpoint],\n",
        "    )\n",
        "\n",
        "    seq_model.load_weights(filepath)\n",
        "    _, accuracy = seq_model.evaluate([test_data[0], test_data[1]], test_labels)\n",
        "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
        "\n",
        "    return history, seq_model\n",
        "\n",
        "\n",
        "_, sequence_model = run_experiment()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "23/23 [==============================] - ETA: 0s - loss: 0.5530 - accuracy: 0.1518\n",
            "Epoch 00001: val_loss improved from inf to 0.52345, saving model to /tmp/video_classifier\n",
            "23/23 [==============================] - 34s 1s/step - loss: 0.5530 - accuracy: 0.1518 - val_loss: 0.5235 - val_accuracy: 0.1178\n",
            "Epoch 2/20\n",
            "23/23 [==============================] - ETA: 0s - loss: 0.5530 - accuracy: 0.1518\n",
            "Epoch 00002: val_loss did not improve from 0.52345\n",
            "23/23 [==============================] - 23s 1s/step - loss: 0.5530 - accuracy: 0.1518 - val_loss: 0.5235 - val_accuracy: 0.1178\n",
            "Epoch 3/20\n",
            "23/23 [==============================] - ETA: 0s - loss: 0.5530 - accuracy: 0.1518\n",
            "Epoch 00003: val_loss did not improve from 0.52345\n",
            "23/23 [==============================] - 23s 1s/step - loss: 0.5530 - accuracy: 0.1518 - val_loss: 0.5235 - val_accuracy: 0.1178\n",
            "Epoch 4/20\n",
            "23/23 [==============================] - ETA: 0s - loss: 0.5530 - accuracy: 0.1518\n",
            "Epoch 00004: val_loss did not improve from 0.52345\n",
            "23/23 [==============================] - 23s 1s/step - loss: 0.5530 - accuracy: 0.1518 - val_loss: 0.5235 - val_accuracy: 0.1178\n",
            "Epoch 5/20\n",
            "23/23 [==============================] - ETA: 0s - loss: 0.5530 - accuracy: 0.1518\n",
            "Epoch 00005: val_loss did not improve from 0.52345\n",
            "23/23 [==============================] - 23s 1s/step - loss: 0.5530 - accuracy: 0.1518 - val_loss: 0.5235 - val_accuracy: 0.1178\n",
            "Epoch 6/20\n",
            "23/23 [==============================] - ETA: 0s - loss: 0.5530 - accuracy: 0.1518\n",
            "Epoch 00006: val_loss did not improve from 0.52345\n",
            "23/23 [==============================] - 23s 1s/step - loss: 0.5530 - accuracy: 0.1518 - val_loss: 0.5235 - val_accuracy: 0.1178\n",
            "Epoch 7/20\n",
            "23/23 [==============================] - ETA: 0s - loss: 0.5530 - accuracy: 0.1518\n",
            "Epoch 00007: val_loss did not improve from 0.52345\n",
            "23/23 [==============================] - 23s 1s/step - loss: 0.5530 - accuracy: 0.1518 - val_loss: 0.5235 - val_accuracy: 0.1178\n",
            "Epoch 8/20\n",
            "23/23 [==============================] - ETA: 0s - loss: 0.5530 - accuracy: 0.1518\n",
            "Epoch 00008: val_loss did not improve from 0.52345\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.5530 - accuracy: 0.1518 - val_loss: 0.5235 - val_accuracy: 0.1178\n",
            "Epoch 9/20\n",
            "23/23 [==============================] - ETA: 0s - loss: 0.5530 - accuracy: 0.1518\n",
            "Epoch 00009: val_loss did not improve from 0.52345\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.5530 - accuracy: 0.1518 - val_loss: 0.5235 - val_accuracy: 0.1178\n",
            "Epoch 10/20\n",
            "23/23 [==============================] - ETA: 0s - loss: 0.5530 - accuracy: 0.1518\n",
            "Epoch 00010: val_loss did not improve from 0.52345\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.5530 - accuracy: 0.1518 - val_loss: 0.5235 - val_accuracy: 0.1178\n",
            "Epoch 11/20\n",
            "23/23 [==============================] - ETA: 0s - loss: 0.5530 - accuracy: 0.1518\n",
            "Epoch 00011: val_loss did not improve from 0.52345\n",
            "23/23 [==============================] - 24s 1s/step - loss: 0.5530 - accuracy: 0.1518 - val_loss: 0.5235 - val_accuracy: 0.1178\n",
            "Epoch 12/20\n",
            "23/23 [==============================] - ETA: 0s - loss: 0.5530 - accuracy: 0.1518\n",
            "Epoch 00012: val_loss did not improve from 0.52345\n",
            "23/23 [==============================] - 23s 1s/step - loss: 0.5530 - accuracy: 0.1518 - val_loss: 0.5235 - val_accuracy: 0.1178\n",
            "Epoch 13/20\n",
            "23/23 [==============================] - ETA: 0s - loss: 0.5530 - accuracy: 0.1518\n",
            "Epoch 00013: val_loss did not improve from 0.52345\n",
            "23/23 [==============================] - 23s 1s/step - loss: 0.5530 - accuracy: 0.1518 - val_loss: 0.5235 - val_accuracy: 0.1178\n",
            "Epoch 14/20\n",
            "23/23 [==============================] - ETA: 0s - loss: 0.5530 - accuracy: 0.1518\n",
            "Epoch 00014: val_loss did not improve from 0.52345\n",
            "23/23 [==============================] - 23s 1s/step - loss: 0.5530 - accuracy: 0.1518 - val_loss: 0.5235 - val_accuracy: 0.1178\n",
            "Epoch 15/20\n",
            "23/23 [==============================] - ETA: 0s - loss: 0.5530 - accuracy: 0.1518\n",
            "Epoch 00015: val_loss did not improve from 0.52345\n",
            "23/23 [==============================] - 23s 1s/step - loss: 0.5530 - accuracy: 0.1518 - val_loss: 0.5235 - val_accuracy: 0.1178\n",
            "Epoch 16/20\n",
            "23/23 [==============================] - ETA: 0s - loss: 0.5530 - accuracy: 0.1518\n",
            "Epoch 00016: val_loss did not improve from 0.52345\n",
            "23/23 [==============================] - 23s 1s/step - loss: 0.5530 - accuracy: 0.1518 - val_loss: 0.5235 - val_accuracy: 0.1178\n",
            "Epoch 17/20\n",
            "23/23 [==============================] - ETA: 0s - loss: 0.5530 - accuracy: 0.1518\n",
            "Epoch 00017: val_loss did not improve from 0.52345\n",
            "23/23 [==============================] - 23s 1s/step - loss: 0.5530 - accuracy: 0.1518 - val_loss: 0.5235 - val_accuracy: 0.1178\n",
            "Epoch 18/20\n",
            "23/23 [==============================] - ETA: 0s - loss: 0.5530 - accuracy: 0.1518\n",
            "Epoch 00018: val_loss did not improve from 0.52345\n",
            "23/23 [==============================] - 23s 1s/step - loss: 0.5530 - accuracy: 0.1518 - val_loss: 0.5235 - val_accuracy: 0.1178\n",
            "Epoch 19/20\n",
            "23/23 [==============================] - ETA: 0s - loss: 0.5530 - accuracy: 0.1518\n",
            "Epoch 00019: val_loss did not improve from 0.52345\n",
            "23/23 [==============================] - 23s 1s/step - loss: 0.5530 - accuracy: 0.1518 - val_loss: 0.5235 - val_accuracy: 0.1178\n",
            "Epoch 20/20\n",
            "23/23 [==============================] - ETA: 0s - loss: 0.5530 - accuracy: 0.1518\n",
            "Epoch 00020: val_loss did not improve from 0.52345\n",
            "23/23 [==============================] - 23s 1s/step - loss: 0.5530 - accuracy: 0.1518 - val_loss: 0.5235 - val_accuracy: 0.1178\n",
            "6/6 [==============================] - 2s 257ms/step - loss: 0.5595 - accuracy: 0.1600\n",
            "Test accuracy: 16.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U677eJkVWGeE"
      },
      "source": [
        "**Note**: To keep the runtime of this example relatively short, we just used a few\n",
        "training examples. This number of training examples is low with respect to the sequence\n",
        "model being used that has 99,909 trainable parameters. You are encouraged to sample more\n",
        "data from the UCF101 dataset using [the notebook](https://colab.research.google.com/github/sayakpaul/Action-Recognition-in-TensorFlow/blob/main/Data_Preparation_UCF101.ipynb) mentioned above and train the same model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63u7q29yWGeF"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 43
        },
        "id": "V8iM7Rv_dVO-",
        "outputId": "652367e5-18a0-4bdb-d7b2-5354ab9d0a14"
      },
      "source": [
        "df[\"path\"][63]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Groin Kick/623.avi'"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "id": "KX76EkcNWGeG",
        "outputId": "a95528de-b058-4e64-cd7f-9ad2ed63958a"
      },
      "source": [
        "\n",
        "def prepare_single_video(frames):\n",
        "    frames = frames[None, ...]\n",
        "    frame_mask = np.zeros(shape=(1, MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
        "    frame_features = np.zeros(shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\")\n",
        "\n",
        "    for i, batch in enumerate(frames):\n",
        "        video_length = batch.shape[0]\n",
        "        length = min(MAX_SEQ_LENGTH, video_length)\n",
        "        for j in range(length):\n",
        "            frame_features[i, j, :] = feature_extractor.predict(batch[None, j, :])\n",
        "        frame_mask[i, :length] = 1  # 1 = not masked, 0 = masked\n",
        "\n",
        "    return frame_features, frame_mask\n",
        "\n",
        "\n",
        "def sequence_prediction(path):\n",
        "    class_vocab = label_processor.get_vocabulary()\n",
        "\n",
        "    frames = load_video(os.path.join(\"test\", path))\n",
        "    frame_features, frame_mask = prepare_single_video(frames)\n",
        "    probabilities = sequence_model.predict([frame_features, frame_mask])[0]\n",
        "\n",
        "    for i in np.argsort(probabilities)[::-1]:\n",
        "        print(f\"  {class_vocab[i]}: {probabilities[i] * 100:5.2f}%\")\n",
        "    return frames\n",
        "\n",
        "\n",
        "# This utility is for visualization.\n",
        "# Referenced from:\n",
        "# https://www.tensorflow.org/hub/tutorials/action_recognition_with_tf_hub\n",
        "def to_gif(images):\n",
        "    converted_images = images.astype(np.uint8)\n",
        "    imageio.mimsave(\"animation.gif\", converted_images, fps=5)\n",
        "    return embed.embed_file(\"animation.gif\")\n",
        "\n",
        "\n",
        "test_video = np.random.choice(test_df[\"path\"].values.tolist())\n",
        "print(f\"Test video path: {test_video}\")\n",
        "test_frames = sequence_prediction(test_video)\n",
        "to_gif(test_frames)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test video path: /content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Bear Hug Attack/1062.avi\n",
            "  8: 10.00%\n",
            "  0:  9.80%\n",
            "  4:  9.80%\n",
            "  6:  9.31%\n",
            "  1:  9.30%\n",
            "  7:  9.19%\n",
            "  10:  8.84%\n",
            "  9:  8.65%\n",
            "  2:  8.51%\n",
            "  5:  8.32%\n",
            "  3:  8.27%\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-124ee23febb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Test video path: {test_video}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mtest_frames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msequence_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_video\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mto_gif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_frames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-29-124ee23febb1>\u001b[0m in \u001b[0;36mto_gif\u001b[0;34m(images)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mto_gif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mconverted_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mimageio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmimsave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"animation.gif\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconverted_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0membed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"animation.gif\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/imageio/core/functions.py\u001b[0m in \u001b[0;36mmimwrite\u001b[0;34m(uri, ims, format, **kwargs)\u001b[0m\n\u001b[1;32m    359\u001b[0m     \u001b[0;31m# be a generator. The damage is done, but we want to error when it happens.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mwritten\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Zero images were written.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[0;31m# Return a result if there is any\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Zero images were written."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKjfnGYkWGeH"
      },
      "source": [
        "## Next steps\n",
        "\n",
        "* In this example, we made use of transfer learning for extracting meaningful features\n",
        "from video frames. You could also fine-tune the pre-trained network to notice how that\n",
        "affects the end results.\n",
        "* For speed-accuracy trade-offs, you can try out other models present inside\n",
        "`tf.keras.applications`.\n",
        "* Try different combinations of `MAX_SEQ_LENGTH` to observe how that affects the\n",
        "performance.\n",
        "* Train on a higher number of classes and see if you are able to get good performance.\n",
        "* Following [this tutorial](https://www.tensorflow.org/hub/tutorials/action_recognition_with_tf_hub), try a\n",
        "[pre-trained action recognition model](https://arxiv.org/abs/1705.07750) from DeepMind.\n",
        "* Rolling-averaging can be useful technique for video classification and it can be\n",
        "combined with a standard image classification model to infer on videos.\n",
        "[This tutorial](https://www.pyimagesearch.com/2019/07/15/video-classification-with-keras-and-deep-learning/)\n",
        "will help understand how to use rolling-averaging with an image classifier.\n",
        "* When there are variations in between the frames of a video not all the frames might be\n",
        "equally important to decide its category. In those situations, putting a\n",
        "[self-attention layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Attention) in the\n",
        "sequence model will likely yield better results.\n",
        "* Following [this book chapter](https://livebook.manning.com/book/deep-learning-with-python-second-edition/chapter-11),\n",
        "you can implement Transformers-based models for processing videos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuXakrD6A9zZ",
        "outputId": "4f077ff8-259f-4dd3-a5ae-f9b8303ecc93"
      },
      "source": [
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.applications import VGG16\n",
        "conv_base = VGG16(weights='imagenet',\n",
        "                  include_top=False,\n",
        "                  input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "\n",
        "num_class = 11\n",
        "\n",
        "def create_base():\n",
        "  conv_base = VGG16(weights='imagenet',\n",
        "                  include_top=False,\n",
        "                  input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "  x = GlobalAveragePooling2D()(conv_base.output)\n",
        "  base_model = Model(conv_base.input, x)\n",
        "  return base_model\n",
        "\n",
        "conv_base = create_base()\n",
        "\n",
        "ip = Input(shape=(10,IMG_SIZE, IMG_SIZE,3))\n",
        "t_conv = TimeDistributed(conv_base)(ip) # vgg16 feature extractor\n",
        "\n",
        "t_lstm = LSTM(10, return_sequences=False)(t_conv)\n",
        "\n",
        "f_softmax = Dense(num_class, activation='softmax')(t_lstm)\n",
        "\n",
        "model = Model(ip, f_softmax)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_27 (InputLayer)       [(None, 10, 224, 224, 3)  0         \n",
            "                             ]                                   \n",
            "                                                                 \n",
            " time_distributed_2 (TimeDis  (None, 10, 512)          14714688  \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 10)                20920     \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 11)                121       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,735,729\n",
            "Trainable params: 14,735,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqbKnJRfBj4N"
      },
      "source": [
        "train_frames = '/content/gdrive/MyDrive/Colab Notebooks/Pose/train_frames'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPEkUIVUNDTn"
      },
      "source": [
        "!mkdir '/content/gdrive/My Drive/Colab Notebooks/Pose/train_frames'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d84KAmiJPQXW"
      },
      "source": [
        "from glob import glob\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJmqDFBqXIj7",
        "outputId": "33003098-b3ff-468c-dd15-dff0f873d2cd"
      },
      "source": [
        "for i in train['path']:\n",
        "  print(i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Groin Kick/686.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Hammer Strike/51.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Ready Stance/2641.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Two handed choked/2964.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Eye Strike/1972.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Bear Hug Attack/1164.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Ready Stance/2743.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Groin Kick/451.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Bear Hug Attack/1359.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Groin Kick/612.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Knee strike/2121.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Hammer Strike/226.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Eye Strike/1942.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Two handed choked/3024.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Eye Strike/1911.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Ready Stance/2733.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Bear Hug Attack/1318.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Two handed choked/2984.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Side Headlock/1663.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Hammer Strike/307.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Hammer Strike/21.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Side Headlock/1642.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Eye Strike/2096.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Ready Stance/2651.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Bear Hug Attack/1123.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Elbow Strike/904.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Bear Hug Attack/1226.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Eye Strike/2045.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Eye Strike/2108.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Groin Kick/653.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Eye Strike/1982.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Hammer Strike/439.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Side Headlock/1673.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Bear Hug Attack/13611.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Two handed choked/2903.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Side Headlock/1591.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Groin Kick/719.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Hands Trapped/1441.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Bear Hug Attack/1032.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Side Headlock/1714.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Eye Strike/1901.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Heel Palm Strike/754.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Groin Kick/664.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Knee strike/2619.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Ready Stance/2692.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Elbow Strike/959.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Groin Kick/582.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Hammer Strike/93.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Knee strike/2509.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Ready Stance/2783.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Ready Stance/2753.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Heel Palm Strike/721.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Groin Kick/623.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Side Headlock/1785.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Eye Strike/1962.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Two handed choked/2974.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Ready Stance/2702.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Hammer Strike/155.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Two handed choked/3004.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Hammer Strike/338.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Bear Hug Attack/1257.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Side Headlock/1622.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Knee strike/2263.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Side Headlock/1724.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Side Headlock/1602.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Knee strike/2519.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Knee strike/2569.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Hammer Strike/61.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Side Headlock/1581.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Two handed choked/2933.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Knee strike/2609.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Heel Palm Strike/765.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Knee strike/2355.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Knee strike/2539.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Knee strike/2426.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Knee strike/2559.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Bear Hug Attack/1287.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Groin Kick/521.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Two handed choked/2923.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Hammer Strike/379.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Hammer Strike/114.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Side Headlock/1734.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Elbow Strike/881.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Hammer Strike/399.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Hammer Strike/31.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Knee strike/2345.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Groin Kick/708.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Hammer Strike/124.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Two handed choked/2943.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Eye Strike/2003.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Hammer Strike/449.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Groin Kick/675.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Side Headlock/1887.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Heel Palm Strike/839.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Bear Hug Attack/1338.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Knee strike/2375.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Knee strike/2162.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Hammer Strike/41.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Hammer Strike/165.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Eye Strike/1952.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Hands Trapped/1523.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Eye Strike/2024.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Bear Hug Attack/1021.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Two handed choked/2872.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Bear Hug Attack/1246.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Bear Hug Attack/1308.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Hammer Strike/256.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Hands Trapped/1543.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Knee strike/2152.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Ready Stance/2681.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Knee strike/2467.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Bear Hug Attack/1154.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Hammer Strike/327.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Two handed choked/2851.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Hammer Strike/71.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Hammer Strike/195.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Heel Palm Strike/819.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Heel Palm Strike/859.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Eye Strike/1921.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Knee strike/2589.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Eye Strike/2035.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Eye Strike/1992.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Knee strike/2599.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Groin Kick/531.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Heel Palm Strike/786.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Bear Hug Attack/991.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Knee strike/2324.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Heel Palm Strike/776.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Hammer Strike/83.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Ready Stance/2712.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Knee strike/2294.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Groin Kick/511.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Bear Hug Attack/1205.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Hands Trapped/1471.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Two handed choked/3045.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Knee strike/2457.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Hands Trapped/1421.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Two handed choked/2811.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Side Headlock/1652.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Hammer Strike/317.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Groin Kick/561.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Side Headlock/1765.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Side Headlock/1755.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Knee strike/2274.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Knee strike/2447.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Knee strike/2385.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Elbow Strike/893.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Side Headlock/1612.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Knee strike/2284.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Bear Hug Attack/13912.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Heel Palm Strike/829.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Hammer Strike/215.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Bear Hug Attack/13812.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Two handed choked/2994.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Bear Hug Attack/1103.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Hands Trapped/1513.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Hands Trapped/1553.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Eye Strike/2014.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Bear Hug Attack/1113.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Hands Trapped/1502.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Bear Hug Attack/1144.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Eye Strike/2055.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Groin Kick/633.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Groin Kick/471.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Ready Stance/2671.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Knee strike/2335.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Bear Hug Attack/1215.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Knee strike/2131.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Elbow Strike/915.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Side Headlock/1704.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Elbow Strike/926.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Groin Kick/697.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Hammer Strike/409.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Bear Hug Attack/1174.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Knee strike/2212.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Ready Stance/2773.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Side Headlock/1571.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Knee strike/2192.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Knee strike/2477.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Groin Kick/592.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Heel Palm Strike/849.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Bear Hug Attack/1267.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Side Headlock/1694.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Two handed choked/2913.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Knee strike/2172.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Two handed choked/2862.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Hammer Strike/11.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Knee strike/2406.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Heel Palm Strike/808.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Knee strike/2365.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Ready Stance/2631.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Side Headlock/1836.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Groin Kick/602.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Bear Hug Attack/1042.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Knee strike/2202.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Side Headlock/1806.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Knee strike/2629.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Hands Trapped/1482.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Knee strike/2529.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Bear Hug Attack/1072.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Bear Hug Attack/1195.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Hammer Strike/348.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Side Headlock/1877.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Side Headlock/1826.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Groin Kick/491.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Hammer Strike/144.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Eye Strike/2066.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Hands Trapped/1431.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Knee strike/2222.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Hammer Strike/246.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Eye Strike/1932.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Two handed choked/2882.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Elbow Strike/9711.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Hammer Strike/276.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Side Headlock/1856.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Side Headlock/1897.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Hammer Strike/369.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Hammer Strike/236.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Two handed choked/2892.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Knee strike/2253.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Bear Hug Attack/1277.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Bear Hug Attack/14012.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Hammer Strike/287.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Hammer Strike/175.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Bear Hug Attack/1185.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Two handed choked/3034.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Two handed choked/2954.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Side Headlock/1816.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Bear Hug Attack/1052.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Bear Hug Attack/1011.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Hands Trapped/1492.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Knee strike/2487.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Knee strike/2232.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Side Headlock/1775.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Side Headlock/1683.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Hands Trapped/1563.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Knee strike/2395.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Ready Stance/2794.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Side Headlock/1846.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Hammer Strike/359.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Bear Hug Attack/1134.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Two handed choked/3014.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Knee strike/2549.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Elbow Strike/9610.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Heel Palm Strike/732.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Bear Hug Attack/14112.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Hammer Strike/297.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Knee strike/2314.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Hammer Strike/266.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Knee strike/2437.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Bear Hug Attack/1349.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Side Headlock/1795.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Bear Hug Attack/1236.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Knee strike/2111.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Groin Kick/481.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Groin Kick/461.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Hammer Strike/104.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Heel Palm Strike/797.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Knee strike/2579.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Bear Hug Attack/981.avi\n",
            "/content/gdrive/My Drive/Colab Notebooks/Pose/pose_data/Escape Side Headlock/1744.avi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0p5IhZ7NZ6Y"
      },
      "source": [
        "# storing the frames from training videos\n",
        "for i in train['path']:\n",
        "    count = 0\n",
        "    cap = cv2.VideoCapture(i)   # capturing the video from the given path\n",
        "    x=1\n",
        "    while(cap.isOpened()):\n",
        "        ret, frame = cap.read()\n",
        "        if (ret != True):\n",
        "            break\n",
        "        filename = i.split('/')[8][:-4] +'_frame'+str(count)+'.jpg'\n",
        "        count += 1\n",
        "        filename.replace('/', '\\\\')\n",
        "        x = cv2.imwrite(filename, frame)\n",
        "        print(x)\n",
        "    cap.release()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G33joDXOVxRA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}